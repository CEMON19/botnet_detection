# -*- coding: utf-8 -*-
"""Testing on XGBoost with test + set.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-GyZ-giHigM-zKZgMB0-TEEOUZY-TmWK
"""

import tensorflow as tf
import pandas as pd
import numpy as np
import pickle
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score
import os
import cv2
import keras
import tensorflow
from keras.models import Sequential,Input,Model
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D
from keras.layers.advanced_activations import LeakyReLU
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.layers import BatchNormalization

from keras.models import model_from_json

columns=[
        'duration',
'protocol_type', 
'service' , 
'flag' ,
 'src_bytes' ,
 'dst_bytes',
'land',
'wrong_fragment',
 'urgent' ,
'hot',
'num_failed_logins',
 'logged_in',
 'num_compromised',
 'root_shell' ,
 'su_attempted' ,
 'num_root' ,
 'num_file_creations' ,
 'num_shells' ,
 'num_access_files',
'num_outbound_cmds' ,
 'is_host_login',
 'is_guest_login',
 'count',
 'srv_count' ,
 'serror_rate' ,
 'srv_serror_rate' ,
 'rerror_rate' ,
 'srv_rerror_rate' ,
 'same_srv_rate' ,
 'diff_srv_rate' ,
 'srv_diff_host_rate',
 'dst_host_count',
 'dst_host_srv_count' ,
 'dst_host_same_srv_rate' ,
 'dst_host_diff_srv_rate' ,
 'dst_host_same_src_port_rate' ,
 'dst_host_srv_diff_host_rate' ,
 'dst_host_serror_rate' ,
 'dst_host_srv_serror_rate' ,
 'dst_host_rerror_rate',
 'dst_host_srv_rerror_rate' ,
 'class'
]

def Standardization(X_original):
  scaler1 = StandardScaler().fit(X)
  X_original=scaler1.transform(X)
  return X_original

data=pd.read_csv("KDDTest+ Unwanted Data Removed.txt")

data.columns=columns

print(data.describe())

for i in columns:
  if type(data[i][0])==type(data['protocol_type'][0]):
    print(i+" column has "+str(data[i].nunique())+" unique features")



cat_col=['protocol_type','service','flag','class']
new_categorical_columns=data[cat_col]
new_categorical_columns.head()

new_cat_encoded=new_categorical_columns.apply(LabelEncoder().fit_transform)

print(new_cat_encoded.head())

data=data.drop(['flag','protocol_type','service'],axis=1)

data=data.drop('class',axis=1)

data=data.join(new_cat_encoded)

data = data.reindex(columns, axis=1)
print(data.head())

X = data.drop('class',1)

X = data.drop(['land','urgent','num_failed_logins','root_shell','su_attempted','num_root' ,'num_shells',
'num_access_files','num_outbound_cmds','is_host_login','serror_rate','srv_rerror_rate'],1)

#Standardizing X 
X_test=Standardization(X)

import pickle
filename='/content/kmeans_cluster.pkl'
infile = open(filename,'rb')
kmeans = pickle.load(infile)
Y_test_new=kmeans.predict(X_test)

filename='/content/xgboost_kmeans.pkl'
infile = open(filename,'rb')
xgb_multi = pickle.load(infile)
print(Y_pred=xgb_multi.predict(X_test))


print(accuracy_score(Y_pred,Y_test_new))

filename='/content/LR_kmeans.pkl'
infile = open(filename,'rb')
LR_multi = pickle.load(infile)
Y_pred=LR_multi.predict(X_test)
print(accuracy_score(Y_pred,Y_test_new))

filename='/content/svm_kmeans.pkl'
infile = open(filename,'rb')
svm_multi = pickle.load(infile)
Y_pred=svm_multi.predict(X_test)
print(accuracy_score(Y_pred,Y_test_new))

"""For CNN Model testing"""


Y_test_new = to_categorical(Y_test_new)

def convertToImage(X_original):
  x=list()
  count=0
  for i in X_original:
    array = np.reshape(i, (5,6))
    print(count)
    count+=1
    img=np.reshape(array,(array.shape[0],array.shape[1],1))
    x.append(img)
  X=np.array(x)
  return X

X_images=convertToImage(X_test)

def loadModels(datadir,weightFile):
  json_file = open(datadir, 'r')
  loaded_model_json = json_file.read()
  json_file.close()
  loaded_model = model_from_json(loaded_model_json)
# load weights into new model
  loaded_model.load_weights(weightFile)
  print("Loaded model from disk")
  return loaded_model

CNN=loadModels('/content/CNN_kmeans.json','CNN_kmeans.h5')

y_pred=CNN.predict(X_images)

print(y_pred)

class_labels = np.argmax(y_pred, axis=1)
Y_test_new = np.argmax(Y_test_new, axis=1)

print(class_labels)
print(Y_test_new)

print(accuracy_score(class_labels,Y_test_new))

y_pred_main=[]
for i in y_pred:
  yp=np.around(i)
  yp=np.where(yp==-0.0,0.0,yp)
  y_pred_main.append(yp)
#y_pred_main=np.array(y_pred_main)
#Y_test_new=np.array(Y_test_new)

"""ACCURACY:

1.XGBOOST=94.5%

2.LR=98.1%

3.SVM=97.05%

4.CNN=95.0%
"""